{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入相关库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准备构建神经网络模型所需的工具和环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像参数\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "img_channels = 3\n",
    "\n",
    "# GAN 参数\n",
    "latent_dim = 100\n",
    "generator_input_shape = (latent_dim,)\n",
    "discriminator_input_shape = (img_height, img_width, img_channels)\n",
    "\n",
    "# 训练参数\n",
    "batch_size = 64\n",
    "epochs = 500\n",
    "learning_rate = 0.0002\n",
    "beta_1 = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练生成对抗网络（GAN）的关键参数。下面是各个参数的解释：\n",
    "img_height: 图像的高度。在这个示例中，图像的高度被设置为32个像素。\n",
    "img_width: 图像的宽度。在这个示例中，图像的宽度也被设置为32个像素。\n",
    "img_channels: 图像的通道数。在这个示例中，图像的通道数被设置为3，代表RGB彩色图像。\n",
    "latent_dim: 潜在空间的维度。潜在空间是生成器模型的输入，它是一个随机向量。在这个示例中，潜在空间的维度被设置为100。\n",
    "generator_input_shape: 生成器模型的输入形状。在这个示例中，生成器的输入形状是一个大小为100的一维向量。\n",
    "discriminator_input_shape: 判别器模型的输入形状。在这个示例中，判别器的输入形状是一个大小为(32, 32, 3)的三维张量，代表着32x32像素的RGB彩色图像。\n",
    "batch_size: 每次训练时用于更新模型的样本数量。在这个示例中，每次训练使用64个样本进行更新。\n",
    "epochs: 训练的轮数。在这个示例中，训练将进行500轮。\n",
    "learning_rate: 学习率。学习率决定了模型参数在每次迭代中的更新幅度。在这个示例中，学习率被设置为0.0002。\n",
    "beta_1: Adam优化器中的beta_1参数。Adam优化器是一种常用的优化算法，beta_1参数控制了梯度的一阶矩估计的衰减率。在这个示例中，beta_1被设置为0.5。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义生成器和判别器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成器模型\n",
    "def build_generator(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(128 * 8 * 8, use_bias=False, input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Reshape((8, 8, 128)),\n",
    "\n",
    "        layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.LeakyReLU(),\n",
    "\n",
    "        layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "#判别器模型\n",
    "def build_discriminator(input_shape):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=input_shape),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'),\n",
    "        layers.LeakyReLU(),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers.Dense：全连接层，将输入数据展平为12888维度。\n",
    "layers.BatchNormalization：批归一化层，用于加速训练过程。\n",
    "layers.LeakyReLU：LeakyReLU激活函数，通过引入负数部分来增强模型的表达能力。\n",
    "layers.Reshape：重塑层，将数据重塑为8x8x128的形状。\n",
    "layers.Conv2DTranspose：反卷积层，用于将数据从低维度映射到高维度。\n",
    "layers.BatchNormalization和layers.LeakyReLU：再次使用批归一化层和LeakyReLU激活函数。\n",
    "layers.Conv2DTranspose：再次使用反卷积层，将数据从低维度映射到3维度（RGB图像通道）。\n",
    "activation='tanh'：最后一层使用tanh激活函数，将输出值限定在[-1,1]范围内。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化生成器和判别器，并定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "D:\\Anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#初始化生成器和判别器\n",
    "generator = build_generator(generator_input_shape)\n",
    "discriminator = build_discriminator(discriminator_input_shape)\n",
    "\n",
    "#定义损失函数\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "#定义优化器\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta_1)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=beta_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化生成器和判别器：调用了前面定义的build_generator和build_discriminator函数，分别创建了生成器（generator）和判别器（discriminator）模型。\n",
    "\n",
    "定义损失函数：使用tf.keras.losses.BinaryCrossentropy函数创建了一个二分类交叉熵损失函数cross_entropy。\n",
    "对于判别器，真实数据的损失是判别器输出与全1向量之间的交叉熵，虚假数据的损失是判别器输出与全0向量之间的交叉熵。\n",
    "生成器的损失是判别器对虚假数据的输出与全1向量之间的交叉熵。\n",
    "\n",
    "定义优化器：使用tf.keras.optimizers.Adam函数创建了两个Adam优化器，分别用于更新生成器和判别器的参数。\n",
    "learning_rate参数控制学习率的大小，beta_1参数是Adam优化器中的指数衰减率，用于控制一阶矩估计的权重。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载cifa-10数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in range(1, 6):\n",
    "        filename = f'C:/Users/Starfish/Desktop/单佳震/cifar-10-batches-py/data_batch_{i}'\n",
    "        with open(filename, 'rb') as f:\n",
    "            batch = pickle.load(f, encoding='bytes')\n",
    "            data.append(batch[b'data'])\n",
    "            labels += batch[b'labels']\n",
    "    data = np.concatenate(data)\n",
    "    data = data.reshape((-1, img_channels, img_height, img_width)).transpose(0, 2, 3, 1) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    return data, labels\n",
    "\n",
    "train_images, train_labels = load_cifar10_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义训练步骤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([batch_size, latent_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = generator(noise, training=True)\n",
    "\n",
    "        real_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████| 100/100 [00:05<00:00, 19.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    sleep(0.05)\n",
    "\n",
    "def train(dataset, epochs):\n",
    "    num_examples_to_generate = 32\n",
    "\n",
    "    generator_losses = []\n",
    "    discriminator_losses = []\n",
    "    epoch_numbers = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(dataset), batch_size):\n",
    "            images = dataset[i:i+batch_size]\n",
    "            train_step(images)\n",
    "\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "            noise = tf.random.normal([num_examples_to_generate, latent_dim])\n",
    "            generated_images = generator(noise, training=False)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for j in range(num_examples_to_generate):\n",
    "                plt.subplot(4, 8, j+1)\n",
    "                plt.imshow((generated_images[j, :, :, :] + 1) / 2)\n",
    "                plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            noise = tf.random.normal([batch_size, latent_dim])\n",
    "            generated_images = generator(noise, training=False)\n",
    "\n",
    "            real_output = discriminator(images, training=False)\n",
    "            fake_output = discriminator(generated_images, training=False)\n",
    "\n",
    "            gen_loss = generator_loss(fake_output)\n",
    "            disc_loss = discriminator_loss(real_output, fake_output)\n",
    "            generator_losses.append(gen_loss)\n",
    "            discriminator_losses.append(disc_loss)\n",
    "            epoch_numbers.append(epoch + 1)\n",
    "\n",
    "            print(f\"Generator Loss: {gen_loss}\")\n",
    "            print(f\"Discriminator Loss: {disc_loss}\")\n",
    "\n",
    "            \n",
    "    return epoch_numbers, generator_losses, discriminator_losses\n",
    "\n",
    "\n",
    "# 调用训练函数\n",
    "epoch_numbers, generator_losses, discriminator_losses = train(train_images, epochs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制损失曲线\n",
    "plt.plot(epoch_numbers, generator_losses, label=\"Generator Loss\")\n",
    "plt.plot(epoch_numbers, discriminator_losses, label=\"Discriminator Loss\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator and Discriminator Losses-单佳震')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_gan(generator, discriminator, test_data):\n",
    "    # 生成图像质量评估\n",
    "    noise = tf.random.normal([10, latent_dim])\n",
    "    generated_images = generator(noise, training=False)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    for i in range(10):\n",
    "        plt.subplot(2, 10, i + 1)\n",
    "        plt.imshow((generated_images[i] + 1) / 2)\n",
    "        plt.title('Generated')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 10, i + 11)\n",
    "        plt.imshow((test_data[i] + 1) / 2)\n",
    "        plt.title('Real')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # 判别器准确率\n",
    "    real_output = discriminator(test_data, training=False)\n",
    "    fake_output = discriminator(generated_images, training=False)\n",
    "    accuracy_real = np.mean(real_output > 0.5)\n",
    "    accuracy_fake = np.mean(fake_output < 0.5)\n",
    "    print(\"Discriminator Accuracy (Real):\", accuracy_real)\n",
    "    print(\"Discriminator Accuracy (Fake):\", accuracy_fake)\n",
    "    \n",
    "#加载测试数据    \n",
    "def load_cifar10_testdata():\n",
    "    data = []\n",
    "    labels = []\n",
    "    filename = f'C:/Users/Starfish/Desktop/单佳震/cifar-10-batches-py/test_batch'\n",
    "    with open(filename, 'rb') as f:\n",
    "        batch = pickle.load(f, encoding='bytes')\n",
    "        data.append(batch[b'data'])\n",
    "        labels += batch[b'labels']\n",
    "    data = np.concatenate(data)\n",
    "    data = data.reshape((-1, img_channels, img_height, img_width)).transpose(0, 2, 3, 1) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    return data, labels\n",
    "\n",
    "# 使用测试数据集评估GAN模型\n",
    "test_data, _ = load_cifar10_testdata()\n",
    "evaluate_gan(generator, discriminator, test_data[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这段代码的作用是评估一个已经训练好的GAN模型的生成能力和判别器的准确率。\n",
    "1. evaluate_gan函数：该函数接收一个生成器模型、一个判别器模型和测试数据集作为输入，然后使用生成器模型生成10张图像并与对应的真实图像一起显示出来。接着，它通过判别器模型对这些图像进行分类，并计算出判别器在真实图像和伪造图像上的准确率。\n",
    "2. load_cifar10_testdata函数：该函数从CIFAR-10测试数据集中加载测试图像和标签，并将数据归一化到[0, 1]范围内。\n",
    "\n",
    "评估GAN模型的性能，了解在生成逼真图像方面的能力以及判别器准确率。通过这些信息，我们可以判断模型是否需要进行调整或改进。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对抗攻击实验"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一次对抗攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adversarial_samples(data, generator, epsilon=0.1):\n",
    "    adv_samples = []\n",
    "    for image in data:\n",
    "        noise = tf.random.normal([1, latent_dim])\n",
    "        generated_image = generator(noise, training=False)\n",
    "\n",
    "        perturbation = epsilon * (generated_image - image)\n",
    "        adv_image = tf.clip_by_value(image + perturbation, -1, 1)\n",
    "        adv_samples.append(adv_image)\n",
    "    return tf.concat(adv_samples, axis=0)\n",
    "\n",
    "# 生成对抗样本\n",
    "epsilon = 0.5  # 调整扰动的大小\n",
    "adversarial_samples = generate_adversarial_samples(test_data[:10], generator, epsilon)\n",
    "\n",
    "# 可视化对抗样本和原始图像\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow((test_data[i] + 1) / 2)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 10, i + 11)\n",
    "    plt.imshow((adversarial_samples[i] + 1) / 2)\n",
    "    plt.title('Adversarial')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def evaluate_model(model, data, labels):\n",
    "    predictions = model.predict(data)\n",
    "    accuracy = np.mean(np.argmax(predictions, axis=1) == labels)\n",
    "    return accuracy\n",
    "\n",
    "# 原始图像评估\n",
    "original_accuracy = evaluate_model(discriminator, test_data[:10], np.ones(10))\n",
    "print(\"Original Accuracy:\", original_accuracy)\n",
    "\n",
    "\n",
    "# 对抗样本评估\n",
    "adversarial_accuracy = evaluate_model(discriminator, adversarial_samples, np.zeros(10))\n",
    "print(\"Adversarial Accuracy:\", adversarial_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二次对抗攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成对抗样本\n",
    "epsilon = 0.3  # 调整扰动的大小\n",
    "adversarial_samples = generate_adversarial_samples(test_data[10:20], generator, epsilon)\n",
    "\n",
    "# 可视化对抗样本和原始图像\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow((test_data[i+10] + 1) / 2)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 10, i + 11)\n",
    "    plt.imshow((adversarial_samples[i] + 1) / 2)\n",
    "    plt.title('Adversarial')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "def evaluate_model(model, data, labels):\n",
    "    predictions = model.predict(data)\n",
    "    accuracy = np.mean(np.argmax(predictions, axis=1) == labels)\n",
    "    return accuracy\n",
    "\n",
    "# 原始图像评估\n",
    "original_accuracy = evaluate_model(discriminator, test_data[10:20], np.ones(10))\n",
    "print(\"Original Accuracy:\", original_accuracy)\n",
    "\n",
    "\n",
    "# 对抗样本评估\n",
    "adversarial_accuracy = evaluate_model(discriminator, adversarial_samples, np.zeros(10))\n",
    "print(\"Adversarial Accuracy:\", adversarial_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![ee7c1db01caec59b8cfcf434e65980ba.png](https://i.postimg.cc/yd9FC6nh/ee7c1db01caec59b8cfcf434e65980ba.png)](https://postimg.cc/8JpFhS2s)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 11102,
     "sourceId": 15444,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
