{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4f90c70-6679-425e-9f8f-e446683c7c16",
   "metadata": {},
   "source": [
    "#  **机器学习-CIFAR10的代码实现和可视化**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac585b-2687-4291-89be-e37a009fd441",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef1b52e-804d-425c-92ea-b5d643efb896",
   "metadata": {},
   "source": [
    "## **姜洋**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7cd5b-bed6-4c4a-806b-1371b1d0aca9",
   "metadata": {},
   "source": [
    "对于CIFAR10的代码实现和可视化，主要分为以下几个步骤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef27a8-0501-4adc-8a4d-4d8b81d2c804",
   "metadata": {},
   "source": [
    "1.下载CIFAR10图集<p>\n",
    "2.搭建神经网络进行训练<p>\n",
    "3.调用损失函数和优化器<p>\n",
    "4.循环训练<p>\n",
    "5.绘制图表<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf74de6-4f24-4c81-bd0b-f6c49b732c16",
   "metadata": {},
   "source": [
    "引用数据集链接：https://www.kaggle.com/datasets/pankrzysiu/cifar10-python/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f4e31-3ed5-4654-b187-adada9333fae",
   "metadata": {},
   "source": [
    "## **设置**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c780173-bdf3-499a-8b48-f60fbe02aca6",
   "metadata": {},
   "source": [
    "·首先，导入一些必要的模块，例如torch，matplotlib等来搭建神经网络和绘制图形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41dfe0a9-626f-4f02-aa8c-2da60318d6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在Jupyter Notebook中使用matplotlib显示图形\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "# 导入神经网络模块\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "# 导入TensorBoard可视化模块\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80204976-0371-4bcd-9b26-ad6129333666",
   "metadata": {},
   "source": [
    "这段代码是用来导入必要的Python库和模块，<p>\n",
    "包括matplotlib用于绘图，<p>\n",
    "torch用于深度学习，<p>\n",
    "torchvision用于计算机视觉任务，<p>\n",
    "nn用于定义神经网络模型，<p>\n",
    "DataLoader用于加载数据集，<p>\n",
    "SummaryWriter用于将训练过程中的数据写入TensorBoard进行可视化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ee861d-1e5d-4a9e-82d5-9910db5f1f14",
   "metadata": {},
   "source": [
    "## **1.准备数据集**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d2db3-c838-4f7e-aa8c-c5ccecd79b35",
   "metadata": {},
   "source": [
    "### **1.1载CIFAR-10数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efcd1064-969e-49ed-b639-320688bcf2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|█▏   | 41779200/170498071 [01:20<04:07, 519326.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      2\u001b[0m                                           download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      4\u001b[0m                                          download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:66\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\torchvision\\datasets\\cifar.py:140\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m download_and_extract_archive(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename, md5\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtgz_md5)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\torchvision\\datasets\\utils.py:395\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    393\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 395\u001b[0m download_url(url, download_root, filename, md5)\n\u001b[0;32m    397\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\torchvision\\datasets\\utils.py:132\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[1;32m--> 132\u001b[0m     _urlretrieve(url, fpath)\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\site-packages\\torchvision\\datasets\\utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m response\u001b[38;5;241m.\u001b[39mread(chunk_size):\n\u001b[0;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[0;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\http\\client.py:473\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    471\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    472\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 473\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\ssl.py:1315\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1312\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1313\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1314\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mD:\\Anaconda3\\Lib\\ssl.py:1167\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1165\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1167\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1168\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data = torchvision.datasets.CIFAR10(root='../姜洋/data', train=True, transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='../姜洋/data', train=False, transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a882a0-9e23-41c0-acc2-71a95cc40e1e",
   "metadata": {},
   "source": [
    "从CIFAR10数据集中加载测试集，设置数据存储路径为'../data'，进行数据转换为Tensor类型<p>\n",
    "若加载成功，则输出提示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a189104b-bcc4-4705-9d74-81016e092125",
   "metadata": {},
   "source": [
    "### **1.2DataLoader加载数据集**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81969326-11d2-4dd7-8aa0-c069152a5425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e95600-7eb7-482c-afec-f6fdab34a52b",
   "metadata": {},
   "source": [
    "train_dataloader：这个 DataLoader 实例是用来加载训练数据的。它从名为 train_data 的数据集中每次提取64个样本（例如图像或文本记录），作为一个小批量数据用于模型训练。这里默认没有显式设置 shuffle 参数，但通常在训练数据加载时应设置为 True 以获得更好的训练效果。\n",
    "<p>\n",
    "\r\n",
    "test_dataloader：这个 DataLoader 实例则是用于加载测试数据的，同样每次提取64个样本作为一个批次。对于测试数据，我们通常不进行随机打乱，以保持数据的原始分布特性，因此默认设置（不显式设置 shuffle 参数，默认为 False）是合适的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f2f3c3-79d0-4eb7-9f8c-55247852aefd",
   "metadata": {},
   "source": [
    "## **2.搭建神经网络**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ff4f4-a72d-421d-bcfc-e73cc6d0a042",
   "metadata": {},
   "source": [
    "### **2.1搭建网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edda878-ba68-4e78-9feb-5f03727fe397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搭建神经网络\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, 1, 2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 4 * 4, 64),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5d094-34fb-4a30-b5dd-57bc023414f2",
   "metadata": {},
   "source": [
    "这段代码定义了一个基于PyTorch的神经网络模型类，继承自nn.Module，用于处理图像分类任务，特别是针对像CIFAR-10这样的数据集。下面是对该模型结构的详细解析：<p>\r",
    "\r\n",
    "初始化方法 (__init__)\r\n",
    "在初始化方法中，模型通过nn.Sequential容器定义了一系列层，这意味着数据会依次通过这些层。这是一个典型的卷积神经网络（CNN）架构，适用于图像识别任务，包括以下组件：\r\n",
    "\r\n",
    "卷积层 (nn.Con vd):\r\n",
    "\r\n",
    "第一个nn.Conv2d(3, 32, 5, 1, 2)表示从3个输入通道（对应RGB图像）到32个输出通道的卷积，卷积核大小为5x5，步长(stride)为1，填充(padding)为2。填充可以在不减小输入尺寸的情况下应用卷积。\r\n",
    "接下来的两个卷积层也遵循相似的模式，但第二个卷积层的输入通道数变为32，第三个变为64，以增加模型的深度和学习复杂特征的能力。\r\n",
    "最大池化层 (nn.Maxool2d):\r\n",
    "\r\n",
    "在每个卷积层之后紧接着一个最大池化层，池化窗口大小为2x2，这有助于缩小空间维度，减少计算量，同\n",
    "时保持重要的特征信息。\r\n",
    "展平层 ( n.Flatten):\r\n",
    "\r\n",
    "经过一系列卷积和池化后，数据被展平成一维向量，准备送入全连接层。此处未直接指定展平后的尺寸，但根据前面的计算，假设输入图像尺寸为32x32，最终展平尺寸为64 * 4 * 4。\r\n",
    "全连 \n",
    "层 (nn.Linear):\r\n",
    "\r\n",
    "展平后的数据首先通过一个拥有64个输出节点的全连接层，然后通过另一个具有10个输出节点的全连接层。10个输出对应CIFAR-10数据集中的10个类别。\r\n",
    "前向传播 (forward)\r\n",
    "forward方法定义了数据通过网络的流程。在这个例子中，非常简洁，仅需一行代码x = self.model(x)，因为所有层已经被组织在self.model中。模型接收输入x，经过各层的变换，最后返回模型的输出，即对输入图像的类别预测。\r\n",
    "\r\n",
    "综上所述，这个模型是一个相对简单的CNN，适合处理像CIFAR-10这样的小型图像分类任务，通过卷积层提取特征，池化层降低空间维度，全连接层进行分类决策。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ed811-2432-43bd-a6d3-3bd2b1534d79",
   "metadata": {},
   "source": [
    "### **2.2创建网络模型***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7780c8-b685-4229-a209-c538a161bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建网络模型\n",
    "model = Model().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ec1be-2ee8-4d26-ab2e-0e27654786eb",
   "metadata": {},
   "source": [
    "实例化神经网络模型并将其移动到GPU上"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff444b29-22f3-4362-a76d-9e8723f37686",
   "metadata": {},
   "source": [
    "model = Model().cuda()：\n",
    "这一行代码首先实例化了之前定义的Model类，创建了一个神经网络模型的实例。\n",
    "然后，通过调用.cuda()方法，该模型被转移到CUDA支持的GPU上（如果可用）。\n",
    "这一步骤对于加速训练过程特别重要，因为GPU相比CPU能更高效地执行大规模并行计算，这对于深度学习任务尤其有利。\n",
    "如果GPU不可用，这段代码会抛出错误，此时需要取消.cuda()调用或者配置合适的环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895839e-db28-440c-8844-911e98645c5d",
   "metadata": {},
   "source": [
    "### **2.3添加tensorboard可视化数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f541de57-b72f-49e4-a80d-9bba88563b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加tensorboard可视化数据\n",
    "writer = SummaryWriter('../logs_tensorboard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c9546-8bf2-4338-9e06-70982ada96fd",
   "metadata": {},
   "source": [
    "设置TensorBoard可视化工具来跟踪训练过程中的各种指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7ebdf4-54f2-43bb-ac0c-733f68983e9f",
   "metadata": {},
   "source": [
    "这一行代码引入了TensorBoard的使用，TensorBoard是TensorFlow提供的一个强大的可视化工具，\n",
    "但也可以与PyTorch很好地集成，用于监控训练过程中的各种数据，比如损失(loss)、准确率(accuracy)、学习率(lr)的变化，以及模型权重(weight)和梯度(gradient)的分布等。\n",
    "通过创建一个SummaryWriter实例并指定日志保存的目录（在这里是../logs_tensorboard），你可以开始记录训练过程中的数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143b63a2-b2c4-474e-be68-7334c2ec451e",
   "metadata": {},
   "source": [
    "## **3.调用损失函数和优化器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e1e1f-4074-4b3a-a2eb-cf54920f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数\n",
    "loss = nn.CrossEntropyLoss().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27902659-265c-41e6-b0cd-1e6326f35df2",
   "metadata": {},
   "source": [
    "nn.CrossEntropyLoss: 这个损失函数实际上是两个操作的组合：nn.LogSoftmax和nn.NLLLoss(负对数似然损失)。它直接从原始概率分数（通常是模型输出，未经过softmax处理）计算交叉熵损失，非常适合网络的输出层直接输出类别概率预测的情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d78add6-312e-449b-9c25-dc07ad95e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1756899-b78e-4783-b8a8-80806c70a6ef",
   "metadata": {},
   "source": [
    "torch.optim.SGD: 这是PyTorch中SGD优化器的类。SGD的基本思想是在每一次迭代中，根据损失函数关于模型参数的梯度来更新参数，从而逐步减小损失，达到优化模型的目的。SGD因其简单和有效性，在许多场景下都是首选的优化策略。\n",
    "\n",
    "model.parameters(): 这个方法返回模型中所有可学习参数（权重和偏置）的迭代器。优化器需要知道哪些参数需要在训练过程中进行更新，model.parameters()就提供了这些参数的访问。\n",
    "\n",
    "lr=0.01: 这里设置的学习率（learning rate，lr）为0.01。学习率决定了参数在梯度下降过程中的更新幅度，即每一步沿着梯度方向调整参数的步长。选择合适的学习率至关重要，因为它影响到模型收敛的速度和最终的性能。较大的学习率可能导致训练不稳定，难以收敛；而过小的学习率则可能使训练过程过于缓慢，甚至陷于局部最小值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32da110-4066-4fd2-b565-db5dd96a1a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建列表来存储准确度数值\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "train_accuracy_list = []\n",
    "test_accuracy_list = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffa31ad-463d-4b74-aea2-a58aeb885813",
   "metadata": {},
   "source": [
    "创建列表来存储准确度数值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b1a15c-06b3-4881-8c33-df78798996c3",
   "metadata": {},
   "source": [
    "## **4.循环训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b81dc5a-5f02-445c-a6c6-b6198bc19a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始循环训练\n",
    "for epoch in range(30):\n",
    "    num_time = 0\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_accurate = 0\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        imgs = imgs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        output = model(imgs)\n",
    "        loss_in = loss(output, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss_in.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss_in.item()\n",
    "        train_accurate += (output.argmax(1) == targets).sum()\n",
    "        num_time += 1\n",
    "\n",
    "    train_loss /= num_time\n",
    "    train_accuracy = train_accurate.item() / len(train_data) * 100\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_accurate = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            imgs = imgs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            output = model(imgs)\n",
    "            loss_in = loss(output, targets)\n",
    "            test_loss += loss_in.item()\n",
    "            test_accurate += (output.argmax(1) == targets).sum()\n",
    "\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_accuracy = test_accurate.item() / len(test_data) * 100\n",
    "    test_loss_list.append(test_loss)\n",
    "    test_accuracy_list.append(test_accuracy)\n",
    "\n",
    "    print('第{}轮测试集的正确率:{:.2f}%'.format(epoch + 1, test_accuracy))\n",
    "\n",
    "    torch.save(model, 'C:/Users/Starfish/Desktop/work/save/model_{}.pth'.format(epoch + 1))\n",
    "    print(\"第{}轮模型训练数据已保存\".format(epoch + 1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c372229-3e3c-41c2-98ae-ef6b070e802e",
   "metadata": {},
   "source": [
    "#### **代码解析**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f441d6b5-eada-485b-b736-00877b776c92",
   "metadata": {},
   "source": [
    "训练循环\n",
    "外层循环: for epoch in range(30) 定义了训练的总轮次（epochs），这里是30轮。\n",
    "\n",
    "模型训练模式: model.train() 将模型设置为训练模式，这一步是必要的，因为某些层（如Dropout、BatchNorm等）在训练和评估模式下的行为不同。\n",
    "\n",
    "遍历训练数据: 通过遍历train_dataloader，对每一批训练数据执行以下操作：\n",
    "\n",
    "数据移到GPU：imgs = imgs.cuda(); targets = targets.cuda()。\n",
    "前向传播：output = model(imgs)。\n",
    "计算损失：loss_in = loss(output, targets)。\n",
    "清零梯度：optimizer.zero_grad()，防止梯度累加。\n",
    "反向传播：loss_in.backward()，计算梯度。\n",
    "更新权重：optimizer.step()，根据梯度更新模型参数。\n",
    "模型评估模式: model.eval() 将模型切换到评估模式，禁用训练时特有的操作，保证评估结果的准确性。\n",
    "\n",
    "遍历测试数据: 使用with torch.no_grad():上下文管理器禁用梯度计算，减少内存消耗和计算开销，然后遍历test_dataloader进行评估。\n",
    "\n",
    "计算测试损失累计和准确率：sum_loss += loss_in; accurate += (output.argmax(1) == targets).sum()。\n",
    "计算整体准确率: 计算一轮结束后在测试集上的平均准确率，并打印结果。\n",
    "\n",
    "模型保存: 每轮训练结束后，使用torch.save(model, '路径')保存模型到指定路径，文件名包含当前轮次。\n",
    "\n",
    "日志关闭: 最后，writer.close()关闭TensorBoard的SummaryWriter，完成日志记录。\n",
    "\n",
    "注意点\n",
    "准确率计算: accuracy = accurate.item() / len(test_data) * 100，注意这里直接使用了len(test_data)来计算总数，实际上应该使用len(test_dataloader.dataset)，因为dataloader可能在最后一个batch中不足一个batch_size的数据，直接使用test_data长度可能导致准确率计算不精确。\n",
    "变量定义: 代码中提及的epoch_list和accuracy_list用于记录每个epoch的信息，但它们在代码片段中未定义，需要在循环外部提前定义。\n",
    "保存路径: 确保模型保存路径是存在的，否则会抛出异常。\n",
    "以上就是该段代码的核心逻辑，涵盖了模型训练、验证、模型保存及TensorBoard日志管理的关键步骤。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0963acb1-185d-4244-be88-e9d94e7b91a9",
   "metadata": {},
   "source": [
    "## **5.绘制图表**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e758b2-50eb-4492-b30a-5b34605e6b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the loss and accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='SimHei', size=13)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot the loss\n",
    "ax1.plot(train_loss_list, label='Train Loss')\n",
    "ax1.plot(test_loss_list, label='Test Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('CIFAR10图集训练前后损失率对比图-姜洋')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot the accuracy\n",
    "ax2.plot(train_accuracy_list, label='Train Accuracy')\n",
    "ax2.plot(test_accuracy_list, label='Test Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('CIFAR10图集训练前后正确率对比图-姜洋')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120a0006-763b-4e3c-8b90-346be6fac107",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
